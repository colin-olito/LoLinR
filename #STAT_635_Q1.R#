data=read.csv("taxes.csv",header=T)
data=data[,c(1,8)]
data=na.omit(data)
length(data[,1])  #should equal 107
par(mfrow=c(2,2))
I=matrix(c(1,0,0,1),nrow=2, ncol=2)
d=rep(1,107)

x=matrix(,nrow=107,ncol=2)
x[,1]=d
x[,2]=data$price

y=data$tax

b.hat = (solve(t(x) %*% x)) %*% t(x) %*% y
b.hat
y.hat = x %*% b.hat

hat.mat = x%*%(solve(t(x)%*%x))%*%t(x)%*%y
sigma.hat = sum((y-(x%*%b.hat))^2)/length(data$tax)
sigma.hat.unbiased = sum((y-(x%*%b.hat))^2)/(length(data$tax) - 2)

std.resids = (y - y.hat)/sqrt(y.hat)
plot(std.resids~data$price, xlab="Price",ylab="Standardized Residuals",main="Std. Residuals ~ Price")
abline(h=0,col=2)
plot(std.resids~y.hat,xlab="Fitted Values",ylab="Standardized Residuals",main="Std. Residuals ~ Fitted Values")
abline(h=0,col=2)
qqnorm(std.resids,main="QQNorm plot of Std. Residuals")
qqline(std.resids,col=2)
hist(std.resids,xlab="Standardized Residuals", ylab="Density",breaks=10, main="Density Plot of Std. Residuals")



rn <- rnorm(n=length(data$price))
testweights <- abs(rn/sum(rn))
diag(testweights)

wb.hat = (solve(t(x) %*% diag(testweights) %*% x)) %*% t(x) %*% diag(testweights) %*% y
wb.hat
wy.hat = x %*% wb.hat

what.mat = x %*% (solve(t(x) %*% diag(testweights) %*% x)) %*% t(x) %*% diag(testweights) %*% y
wsigma.hat = sum((y-(x %*% wb.hat))^2)/length(data$tax)
wsigma.hat.unbiased = sum((y-(x %*% wb.hat))^2)/(length(data$tax) - 2)




wstd.resids = (y - wy.hat)/sqrt(wy.hat)
plot(wstd.resids~data$price, xlab="Price",ylab="Standardized Residuals",main="Std. Residuals ~ Price")
abline(h=0,col=2)
plot(wstd.resids~y.hat,xlab="Fitted Values",ylab="Standardized Residuals",main="Std. Residuals ~ Fitted Values")
abline(h=0,col=2)
qqnorm(wstd.resids,main="QQNorm plot of Std. Residuals")
qqline(wstd.resids,col=2)
hist(wstd.resids,xlab="Standardized Residuals", ylab="Density",breaks=10, main="Density Plot of Std. Residuals")



lm(data$tax ~ data$price, weights=testweights)











#  triCube is Tukey tricubed weight function
#  first argument, d, is a vector of the
#  distances between the observations and
#  the estimation point second argument, h,
#  is the half window width it returns a vector
#  of weights (w) for the observations in the vector, d


TriCube<-function(d,h) {
  h <- r/2
  n<-length(d)
  zero<-rep(0,n)
  ad<-abs(d)
  w<-(1-(ad/h)^3)^3
  w<-pmax(zero,w)
  return(w)
}










#Log Transformed Data
lx=matrix(,nrow=107,ncol=2)
lx[,1]=d
lx[,2]=log(data$price)
ly=log(data$tax)
lb.hat = (solve(t(lx) %*% lx)) %*% t(lx) %*% ly
lb.hat
ly.hat = lx %*% lb.hat

lsigma.hat = sum((ly-(lx%*%lb.hat))^2)/length(data$tax)
lsigma.hat.unbiased = sum((ly-(lx%*%lb.hat))^2)/(length(data$tax) - 2)

l.std.resids = (ly - ly.hat)/sqrt(ly.hat)
plot(l.std.resids~log(data$price), xlab="Log Price",ylab="Standardized Residuals",main="Std. Residuals of Log Tsf. Data ~ Log Price")
abline(h=0,col=2)
plot(l.std.resids~ly.hat,xlab="Fitted Values",ylab="Standardized Residuals",main="Std. Resids of Log Tsf. Data ~ Fitted Values")
abline(h=0,col=2)
qqnorm(l.std.resids,main="QQNorm Std. Resids of Log Tsf. Data")
qqline(l.std.resids,col=2)
hist(l.std.resids,xlab="Standardized Residuals", ylab="Density",breaks=10, main="Density of Std. Resids of Log Tsf. Data")



#Question 2 part B
sigma.hat.sq=(t(y - (x %*% b.hat)) %*% (y - (x %*% b.hat)))/(length(y) - length(b.hat))
var.b = sigma.hat.unbiased * (solve(t(x) %*% x))



m1=lm(y~x)





#EXPLORING LIKELIHOOD SPACE FOR B1
l=array()
lstar=array()
b1=sort(runif(1000,min=0.5,max=1))
b0=sort(runif(1000,min=-50,max=50))

for (theta in 1:length(b1)){
	for (i in 1:length(data$tax)){
	l [i]= -(1/2)*(data$tax[i] - b1[theta]*data$price[i])^2
	}
	lstar[theta] = sum(l[1:length(data$tax)])
}
plot(lstar~b1)


#EXPLORING LIKELIHOOD SPACE FOR b0

l=array()
lstar=array()
b0=sort(runif(1000,min=-200,max=200))

for (theta in 1:length(b1)){
	for (i in 1:length(data$tax)){
	l [i]= -(1/2)*(data$tax[i] - b0[theta]- 0.70275*data$price[i])^2
	}
	lstar[theta] = sum(l[1:length(data$tax)])
}
plot(lstar~b0)









